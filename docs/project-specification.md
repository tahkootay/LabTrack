# Цель проекта
Создать безопасный сервис для хранения и систематизации медицинских анализов. Пользователь загружает файлы из лабораторий (PDF/сканы/изображения/CSV/HL7/FHIR) или вводит данные вручную. Сервис извлекает структурированные данные напрямую с помощью LLM (включая встроенное OCR), нормализует показатели (коды/единицы/референсы), сохраняет их в БД и показывает удобный интерфейс: общая таблица, карточка анализа, сравнение с предыдущими результатами и с референсными диапазонами, графики динамики, флаги «вне референса». При этом сервис акцентирован на **анонимности**: личные данные пациентов не собираются и не хранятся.

---

## Основные сценарии (User Stories)
1. **Базовый аккаунт (v1)**: сервис работает на примере одного пользователя (один аккаунт по умолчанию). Логина/регистрации пока нет, но архитектура предусматривает возможность добавления личного кабинета и multi-user в следующих версиях.
2. **Загрузка**: как пользователь, я загружаю файл с результатами анализа (PDF/фото/скан/CSV/HL7), вижу статус обработки и уведомление об успешном разборе или причине отказа.
3. **Ручной ввод**: если у меня нет файла, я могу вручную ввести показатели анализа (название, значение, единицы, дата).
4. **Авто-извлечение**: система передаёт файл сразу в LLM (с OCR на её стороне), получает строго по JSON-схеме: метаданные отчёта, список показателей, единицы, референсные диапазоны из бланка, комментарии лаборатории.
5. **Нормализация**: система сопоставляет показатель к унифицированному словарю (например, LOINC), приводит единицы к базовым (ммоль/л, г/л и т. п.) с конвертацией, учитывает пол/возраст/метод для референсов.
6. **Сохранение**: результаты пишутся в БД с версионированием документов и трассировкой этапов обработки.
7. **Просмотр**: я вижу общую таблицу всех моих анализов, могу фильтровать по дате, лаборатории, показателю, панелям.
8. **Сравнение**: в карточке показателя вижу последние результаты, график динамики, сравнение с предыдущим (дельта/тренд) и отметку попадания в референс; подсветка «высокий/низкий».
9. **Аномалии**: если результат отличается от референса более чем в 10 раз, система помечает его как «подозрительное значение» и рекомендует перепроверить вручную.
10. **Валидация/правки**: если система ошиблась, я могу отредактировать имя показателя, единицы, сверить референс, закрепить корректировку маппинга на будущее.
11. **Экспорт/шаринг**: выгрузка в CSV/Excel/PDF (шаринг и мульти-профиль планируются в будущих версиях).

---

## Архитектура (высокоуровнево)
- **Frontend (Web + Mobile-friendly)**: React/Next.js, графики (Recharts/ECharts), состояние (TanStack Query), i18n, доступность (a11y).
- **Backend API**: FastAPI (Python) или NestJS (TypeScript). Авторизация пока не нужна (один аккаунт), но структура API и модели БД предусматривают `user_id` для будущего расширения. RBAC: в будущем user, admin.
- **Файловое хранилище**: S3-совместимое (AWS S3/MinIO). Префиксы по пользователю/документу. Версионирование.
- **Очереди/воркеры**: Celery/RQ (Python) или BullMQ (Node). Задачи: передача файла в LLM → нормализация → сохранение → валидация.
- **LLM-экстракция (с OCR)**: OpenAI Responses API со строгой JSON-схемой и function-calling. Температура низкая, контроль токенов, ретраи. OCR встроен в модель.
- **БД**: PostgreSQL (основные данные) + Redis (кэш/очереди). ORM: SQLAlchemy/Prisma. Версионирование миграций: Alembic.
- **Юнит-конверсии**: библиотека Pint + собственные коэффициенты для медицинских единиц.
- **Справочники**: словарь показателей (анализы/панели/синонимы), опционально LOINC-коды; таблица единиц; таблица лабораторий и их специфики.
- **Анонимность**: в базе не хранятся ФИО, дата рождения и иные персональные данные. Только технические идентификаторы. В будущих версиях при вводе e-mail — без хранения других данных.

---

## Алгоритм пайплайна обработки
1. **Приём файла** → валидация типа/размера → сохранение в S3 → запись в `documents` (status=pending).
2. **LLM-экстракция**: файл напрямую отправляется в LLM (с встроенным OCR для изображений/сканов). Настроить ограничение токенов и ретраи (exponential backoff). Получить **строго JSON**.
3. **Нормализация**:
   - Маппинг `source_label` → `analyte_id` через `mappings` + синонимы.
   - Проверка/конверсия единиц (Pint). Если единица неизвестна → флаг `normalized=false`.
   - Выбор актуального референса: приоритет (lab-specific & method-specific & демография) → иначе дефолт.
   - Расчёт `out_of_range`, `flag`, `z-score` или относительное отклонение.
   - Если значение >10× от референса → флаг `suspect=true`, рекомендация перепроверить.
4. **Сохранение**: запись в `results`, пересчёт `result_links_prev`, вычисление `delta`/`delta_pct`.
5. **Пост-валидация**: правила качества. В случае ошибок — статус `failed` + причина, возможность повторной обработки.

---

## Отличие от классического OCR+парсер подхода
- **Простота**: нет отдельного OCR и парсинга, всё делает LLM.
- **Минус**: зависимость от качества встроенного OCR и от модели.
- **Плюс**: сокращение кода, меньше сервисов, быстрее MVP.
- **Стратегия смягчения**: хранить raw_text (если модель вернула), предусмотреть fallback на внешний OCR при системных сбоях.

---

Итого: в **версии 1** реализуется минимально рабочая система на одного пользователя (без регистрации, без мульти-профиля, без шаринга). Архитектура проектируется так, чтобы в **версии 2** легко добавить: регистрацию по e-mail, личный кабинет, несколько пользователей, мульти-профиль и расширенный шаринг.

**Дополнительно**
1. Создать файл claude.md
2. Сохранять чистосту структуры проекта - не создавать файлы в корне проекта, всё в соответствующи подкаталогах
